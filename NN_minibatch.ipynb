{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_minibatch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST\n",
        "\n",
        "First I download the dataset from https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz and upload it onto colab instance (wget seems to corrupt the files)\n"
      ],
      "metadata": {
        "id": "VF4BzyfdXurP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Then I replicate code from http://neuralnetworksanddeeplearning.com/chap1.html"
      ],
      "metadata": {
        "id": "2OcJ-0IgBgPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "mnist_loader\n",
        "~~~~~~~~~~~~\n",
        "\n",
        "A library to load the MNIST image data.  For details of the data\n",
        "structures that are returned, see the doc strings for ``load_data``\n",
        "and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the\n",
        "function usually called by our neural network code.\n",
        "\"\"\"\n",
        "\n",
        "#### Libraries\n",
        "# Standard library\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "# Third-party libraries\n",
        "import numpy as np\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Return the MNIST data as a tuple containing the training data,\n",
        "    the validation data, and the test data.\n",
        "\n",
        "    The ``training_data`` is returned as a tuple with two entries.\n",
        "    The first entry contains the actual training images.  This is a\n",
        "    numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
        "    numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
        "    pixels in a single MNIST image.\n",
        "\n",
        "    The second entry in the ``training_data`` tuple is a numpy ndarray\n",
        "    containing 50,000 entries.  Those entries are just the digit\n",
        "    values (0...9) for the corresponding images contained in the first\n",
        "    entry of the tuple.\n",
        "\n",
        "    The ``validation_data`` and ``test_data`` are similar, except\n",
        "    each contains only 10,000 images.\n",
        "\n",
        "    This is a nice data format, but for use in neural networks it's\n",
        "    helpful to modify the format of the ``training_data`` a little.\n",
        "    That's done in the wrapper function ``load_data_wrapper()``, see\n",
        "    below.\n",
        "    \"\"\"\n",
        "    # f = gzip.open('../data/mnist.pkl.gz', 'rb')\n",
        "    f = gzip.open('../mnist.pkl.gz', 'rb')\n",
        "    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
        "    f.close()\n",
        "    return (training_data, validation_data, test_data)\n",
        "\n",
        "def load_data_wrapper():\n",
        "    \"\"\"Return a tuple containing ``(training_data, validation_data,\n",
        "    test_data)``. Based on ``load_data``, but the format is more\n",
        "    convenient for use in our implementation of neural networks.\n",
        "\n",
        "    In particular, ``training_data`` is a list containing 50,000\n",
        "    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray\n",
        "    containing the input image.  ``y`` is a 10-dimensional\n",
        "    numpy.ndarray representing the unit vector corresponding to the\n",
        "    correct digit for ``x``.\n",
        "\n",
        "    ``validation_data`` and ``test_data`` are lists containing 10,000\n",
        "    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional\n",
        "    numpy.ndarry containing the input image, and ``y`` is the\n",
        "    corresponding classification, i.e., the digit values (integers)\n",
        "    corresponding to ``x``.\n",
        "\n",
        "    Obviously, this means we're using slightly different formats for\n",
        "    the training data and the validation / test data.  These formats\n",
        "    turn out to be the most convenient for use in our neural network\n",
        "    code.\"\"\"\n",
        "    tr_d, va_d, te_d = load_data()\n",
        "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
        "    training_results = [one_hot_result(y) for y in tr_d[1]]\n",
        "    training_data = zip(training_inputs, training_results)\n",
        "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
        "    validation_data = zip(validation_inputs, va_d[1])\n",
        "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
        "    test_data = zip(test_inputs, te_d[1])\n",
        "    return (training_data, validation_data, test_data)\n",
        "\n",
        "def one_hot_result(j):\n",
        "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
        "    position and zeroes elsewhere.  This is used to convert a digit\n",
        "    (0...9) into a corresponding desired output from the neural\n",
        "    network.\"\"\"\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1.0\n",
        "    return e"
      ],
      "metadata": {
        "id": "nOL5OMt7a7_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_d, va_d, te_d = load_data()\n",
        "print(type(tr_d))\n",
        "print(len(tr_d))\n",
        "print(type(tr_d[0]))\n",
        "print(tr_d[0].shape, tr_d[1].shape, te_d[0].shape, te_d[1].shape)"
      ],
      "metadata": {
        "id": "JWgRFwqAe_AN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ef34b8-5d99-4a23-d3e5-fed360933eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tuple'>\n",
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(50000, 784) (50000,) (10000, 784) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eQ8cIchEV05d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmCB6YlYXq4j"
      },
      "outputs": [],
      "source": [
        "#### Libraries\n",
        "# Standard library\n",
        "import random\n",
        "\n",
        "# Third-party libraries\n",
        "import numpy as np\n",
        "\n",
        "class Network(object):\n",
        "\n",
        "    def __init__(self, sizes):\n",
        "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
        "        respective layers of the network.  For example, if the list\n",
        "        was [2, 3, 1] then it would be a three-layer network, with the\n",
        "        first layer containing 2 neurons, the second layer 3 neurons,\n",
        "        and the third layer 1 neuron.  The biases and weights for the\n",
        "        network are initialized randomly, using a Gaussian\n",
        "        distribution with mean 0, and variance 1.  Note that the first\n",
        "        layer is assumed to be an input layer, and by convention we\n",
        "        won't set any biases for those neurons, since biases are only\n",
        "        ever used in computing the outputs from later layers.\"\"\"\n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
        "        self.weights = [np.random.randn(y, x)\n",
        "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "\n",
        "    def feedforward(self, a):\n",
        "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = sigmoid(np.dot(w, a)+b)\n",
        "        return a\n",
        "\n",
        "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
        "            test_data=None):\n",
        "        \"\"\"Train the neural network using mini-batch stochastic\n",
        "        gradient descent.  The ``training_data`` is a list of tuples\n",
        "        ``(x, y)`` representing the training inputs and the desired\n",
        "        outputs.  The other non-optional parameters are\n",
        "        self-explanatory.  If ``test_data`` is provided then the\n",
        "        network will be evaluated against the test data after each\n",
        "        epoch, and partial progress printed out.  This is useful for\n",
        "        tracking progress, but slows things down substantially.\"\"\"\n",
        "        if test_data: \n",
        "            test_data = list(test_data)\n",
        "            n_test = len(test_data)\n",
        "        \n",
        "        training_data = list(training_data)\n",
        "        n = len(training_data)\n",
        "\n",
        "        for j in range(epochs):\n",
        "            # shuffle the training data every time\n",
        "            random.shuffle(training_data)\n",
        "            # create minibatches of given size\n",
        "            mini_batches = [\n",
        "                training_data[k:k+mini_batch_size]\n",
        "                for k in range(0, n, mini_batch_size)]\n",
        "            # update minibatch using backpropagation\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch, eta)\n",
        "\n",
        "\n",
        "\n",
        "            if test_data:\n",
        "                print(\"Epoch {}: {} / {}\".format(\n",
        "                    j, self.evaluate(test_data), n_test))\n",
        "            else:\n",
        "                print(\"Epoch {} complete\".format(j))\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, eta):\n",
        "        \"\"\"Update the network's weights and biases by applying\n",
        "        gradient descent using backpropagation to a single mini batch.\n",
        "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
        "        is the learning rate.\"\"\"\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "\n",
        "        # create X and Y lists that are going to contain vectors from a minibatch.\n",
        "        # X list contains all the x (input) vectors from the pairs in the minibatch\n",
        "        # Y list contains all the y (label) vectors from the pairs in the minibatch\n",
        "        X = [pair[0] for pair in mini_batch]\n",
        "        Y = [pair[1] for pair in mini_batch]\n",
        "\n",
        "        # In this solution we are passing \"the whole minibatch\" instead of just one pair from \n",
        "        # the minibatch into the backpropagation function\n",
        "        nabla_b, nabla_w = self.backprop(X,Y)\n",
        "\n",
        "\n",
        "        self.weights = [w-(eta/len(mini_batch))*nw\n",
        "                        for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b-(eta/len(mini_batch))*nb\n",
        "                       for b, nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "    def backprop(self, X, Y):\n",
        "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
        "        gradient for the cost function C_x.  ``nabla_b`` and\n",
        "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
        "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "        # Create the np array the same size as biases and weights that are\n",
        "        # going to contain the updated nabla_b and unpdated nabla_w \n",
        "        total_nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        total_nabla_w = [np.zeros(b.shape) for b in self.weights]\n",
        "\n",
        "        # iterate over an element from X and Y paralely at the same time using zip\n",
        "        for column_X, column_Y in zip(X,Y):\n",
        "\n",
        "          activation = column_X # take first column of the X\n",
        "          activations = [column_X] # list to store all the activations, layer by layer\n",
        "\n",
        "          zs = [] # list to store all the z vectors, layer by layer\n",
        "\n",
        "          # feedforward\n",
        "          for b, w in zip(self.biases, self.weights):\n",
        "              z = np.dot(w, activation)+b\n",
        "              zs.append(z)\n",
        "              activation = sigmoid(z)\n",
        "              activations.append(activation)\n",
        "\n",
        "          # Calculate the error in the last layer\n",
        "          delta = self.cost_derivative(activations[-1], column_Y) * \\\n",
        "              sigmoid_prime(zs[-1])\n",
        "\n",
        "          # change in biases with respect to cost is equal to the change in the last layer\n",
        "          nabla_b[-1] = delta\n",
        "          nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
        "          # Note that the variable l in the loop below is used a little\n",
        "          # differently to the notation in Chapter 2 of the book.  Here,\n",
        "          # l = 1 means the last layer of neurons, l = 2 is the\n",
        "          # second-last layer, and so on.  It's a renumbering of the\n",
        "          # scheme in the book, used here to take advantage of the fact\n",
        "          # that Python can use negative indices in lists.\n",
        "\n",
        "          # back pass\n",
        "          for l in range(2, self.num_layers):\n",
        "              z = zs[-l]\n",
        "              sp = sigmoid_prime(z)\n",
        "              delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
        "              nabla_b[-l] = delta\n",
        "              nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
        "\n",
        "          # update the weights and biases\n",
        "          total_nabla_b = [nb+dnb for nb, dnb in zip(total_nabla_b, nabla_b)]\n",
        "          total_nabla_w = [nw+dnw for nw, dnw in zip(total_nabla_w, nabla_w)]\n",
        "\n",
        "        return (total_nabla_b, total_nabla_w)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        \"\"\"Return the number of test inputs for which the neural\n",
        "        network outputs the correct result. Note that the neural\n",
        "        network k's output is assumed to be the index of whichever\n",
        "        neuron in the final layer has the highest activation.\"\"\"\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
        "                        for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
        "        \\partial a for the output activations.\"\"\"\n",
        "        return (output_activations-y)\n",
        "\n",
        "#### Miscellaneous functions\n",
        "def sigmoid(z):\n",
        "    \"\"\"The sigmoid function.\"\"\"\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
        "    return sigmoid(z)*(1-sigmoid(z))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr, v, te = load_data_wrapper()\n",
        "net = Network([784, 30, 10]) "
      ],
      "metadata": {
        "id": "AJ09qJiu8N67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.SGD(tr, 30, 10, 3.0, test_data=te)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzBjyMRB-MeX",
        "outputId": "cdd2d64f-83a9-4c29-b408-b0423e701738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: 9135 / 10000\n",
            "Epoch 1: 9269 / 10000\n",
            "Epoch 2: 9299 / 10000\n",
            "Epoch 3: 9351 / 10000\n",
            "Epoch 4: 9386 / 10000\n",
            "Epoch 5: 9398 / 10000\n",
            "Epoch 6: 9444 / 10000\n",
            "Epoch 7: 9417 / 10000\n",
            "Epoch 8: 9466 / 10000\n",
            "Epoch 9: 9470 / 10000\n",
            "Epoch 10: 9484 / 10000\n",
            "Epoch 11: 9466 / 10000\n",
            "Epoch 12: 9462 / 10000\n",
            "Epoch 13: 9497 / 10000\n",
            "Epoch 14: 9407 / 10000\n",
            "Epoch 15: 9496 / 10000\n",
            "Epoch 16: 9511 / 10000\n",
            "Epoch 17: 9521 / 10000\n",
            "Epoch 18: 9524 / 10000\n",
            "Epoch 19: 9494 / 10000\n",
            "Epoch 20: 9507 / 10000\n",
            "Epoch 21: 9546 / 10000\n",
            "Epoch 22: 9516 / 10000\n",
            "Epoch 23: 9514 / 10000\n",
            "Epoch 24: 9545 / 10000\n",
            "Epoch 25: 9509 / 10000\n",
            "Epoch 26: 9523 / 10000\n",
            "Epoch 27: 9517 / 10000\n",
            "Epoch 28: 9501 / 10000\n",
            "Epoch 29: 9535 / 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr, v, te = load_data_wrapper()"
      ],
      "metadata": {
        "id": "qAwBvR0ZViRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upto = 5\n",
        "for img, lab in te:\n",
        "    pred = net.feedforward(img)\n",
        "    pred_lab = np.argmax(pred)\n",
        "    if pred_lab != lab:\n",
        "        plt.imshow(img.reshape((28, 28)))\n",
        "        plt.show()\n",
        "        print(\"predicted:\", pred_lab, \"actual:\", lab)\n",
        "        upto -= 1\n",
        "    if upto < 1: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CxeRWnGYbZH_",
        "outputId": "ac935067-12ed-4d8f-a34b-45b6416db619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted: 2 actual: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOm0lEQVR4nO3de4xc5XnH8d/jxZdgbMULwV05bh2IQ+tQYdqtDQVRAi0xpqoJihzcxDUp0pILgihJVQSRQiBSXUogVALaNbiYSwxIxMEitIm7SoRIwHhNHF+bLLh2sGt8wcFeQ3zZ3ad/7AGtzZ531zNn5gx+vh9pNDPnmbPn0cDP58x5z8xr7i4AJ74RZTcAoD4IOxAEYQeCIOxAEIQdCOKkem5slI32MRpbz00CoRzUWzrsh2ywWlVhN7NZku6R1CTpAXdfmHr9GI3VTLu0mk0CSFjpHbm1ig/jzaxJ0r2SLpc0TdI8M5tW6d8DUFvVfGafIekVd9/s7oclPS5pTjFtAShaNWGfJOm1Ac+3ZcuOYmZtZtZpZp1HdKiKzQGoRs3Pxrt7u7u3unvrSI2u9eYA5Kgm7NslTR7w/MPZMgANqJqwr5I01cw+YmajJF0taXkxbQEoWsVDb+7eY2bXS/qR+ofeFrv7hsI6A1CoqsbZ3f1ZSc8W1AuAGuJyWSAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4KoahZXND4bOSr9Au9Ll3t6CuwGZaoq7Ga2RVK3pF5JPe7eWkRTAIpXxJ79E+6+p4C/A6CG+MwOBFFt2F3Sj81stZm1DfYCM2szs04z6zyiQ1VuDkClqj2Mv9Ddt5vZ6ZJWmNn/uPtzA1/g7u2S2iVpvDV7ldsDUKGq9uzuvj273yVpmaQZRTQFoHgVh93MxprZuHceS7pM0vqiGgNQrGoO4ydKWmZm7/yd77n7fxXSFY7Lm/PPz60tvv2u5LqrD05O1u9sn5ust3x3ZbKuvt50HXVTcdjdfbOkcwrsBUANMfQGBEHYgSAIOxAEYQeCIOxAEOZev4vaxluzz7RL67a9KJo+flZubdON45Pr3vOJx5L1y0/uTta/tO2iZP21L03JrfnqDcl1cfxWeof2+14brMaeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJwdSd2fOS9ZX/TPdyfr40bkf8X1C5f+XXLd3q7NyTrei3F2AIQdiIKwA0EQdiAIwg4EQdiBIAg7EARTNiNp3BMvJusLxn01Wf/Zt/41t/bb1tOT645nnL1Q7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2VGVUx94IVl/4Ktn5Nb2nDPo167fNX5pRS0hx5B7djNbbGa7zGz9gGXNZrbCzLqy+wm1bRNAtYZzGP+QpFnHLLtJUoe7T5XUkT0H0MCGDLu7Pydp7zGL50hakj1eIunKgvsCULBKP7NPdPcd2ePXJU3Me6GZtUlqk6QxOrnCzQGoVtVn473/Fytzf7XS3dvdvdXdW0dqdLWbA1ChSsO+08xaJCm731VcSwBqodKwL5e0IHu8QNLTxbQDoFaG/MxuZkslXSzpNDPbJumbkhZKetLMrpW0VdLcWjZ5omuamj8WLUmb5+eeEpEkTfrz7bm11/eNS647blm63rwi/Z3ynjNakvUpo57IrZ351IHkuvWb0SCGIcPu7vNySsz2ALyPcLksEARhB4Ig7EAQhB0IgrADQfAV1wI0ndqcrG+75g+T9WU33JGsD/Uv8qpDk3JrY0ccSq57xfkHk/Wf/i699R/uOydZ/3bXFbm18avWJddFsdizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLMXYM9fn5Wsj7lkd7J+2bKvJ+tn/fsbyXrvpq7c2ogxY5Lr3jb33GR95cL7k/WLP/CLZH3u2/nXIByY9rHkur0bf52s4/iwZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnH6ZDV/xZbm3pbf+SXPezt6TH0T/66IvJem+ymtZ3MP199cOnpKdNHsrj3ekJfBdNeSa3tv6Z9AxB3/hiW7I+6kedyTqOxp4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Iw9/pNjDvemn2mvT8nfz17df6/i+NPSo9lr7zk95L13jf2VtTTcOz/2/OS9W/fvihZf/5A+rv6L835aLK++y/yf9P+67d8L7nuJR/4v2T9c1d9IVn3gL9Lv9I7tN/3DnrxxJB7djNbbGa7zGz9gGW3mtl2M1uT3WYX2TCA4g3nMP4hSbMGWX63u0/Pbs8W2xaAog0Zdnd/TlLtjjMB1EU1J+iuN7O12WF+7gXSZtZmZp1m1nlE6XnHANROpWG/X9KZkqZL2iHpO3kvdPd2d29199aRSn/xAUDtVBR2d9/p7r3u3idpkaQZxbYFoGgVhd3MWgY8/ZSk9XmvBdAYhvw+u5ktlXSxpNPMbJukb0q62MymS3JJWyRdV8MeG8KLu6fk1n77fHocffIbPy+4m6M1/dHU3Nq3bnswue7unvHJ+ktX5v9tSerZsjVZn7DlN7m1//hl/tztkqQnf5gsX/VwR7L+g6suyK2lfmv/RDVk2N193iCL0/8HAWg4XC4LBEHYgSAIOxAEYQeCIOxAEHzFdZiO/OWf5tZuuP+J5Lr/dPv8ZP2DD7+QrO/7XPprqn9/y/Lc2m8OnZpcd/U1f5ys963ZmKzX0ojp05L1zw8xNPdm79jc2g/OTw8p9r65L1lvVFV9xRXAiYGwA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0AXfekx8G7Pn1fsn7Ruk8n6898/NFkfcXvWnJrD82+JLlu7yv/m6w3sqHG4e97uj239sVXP5Nc1+bsT9b7uruT9bIwzg6AsANREHYgCMIOBEHYgSAIOxAEYQeCYJy9AE0Tcme/kiRN/M+eZH3aKempiR998JPJ+qRHfpVb693zRnLdE1n31fnXPzx5x53JdR/bd26y/tOZH0rW+95+O1mvFcbZARB2IArCDgRB2IEgCDsQBGEHgiDsQBCMs9fBiLH5v18uSertTZb7Dh4ssBtIkmakfy//kaf+LVm/fuvfJOv7Lnozvf2+9H/zSlU1zm5mk83sJ2a20cw2mNmN2fJmM1thZl3ZffrKEgClGs5hfI+kr7n7NEnnSfqymU2TdJOkDnefKqkjew6gQQ0Zdnff4e4vZ4+7JW2SNEnSHElLspctkXRlrZoEUL2TjufFZjZF0rmSVkqa6O47stLrkibmrNMmqU2SxujkSvsEUKVhn403s1MkPSXpK+5+1K/xef9ZvkHP9Ll7u7u3unvrSI2uqlkAlRtW2M1spPqD/pi7fz9bvNPMWrJ6i6RdtWkRQBGGPIw3M5P0oKRN7n7XgNJySQskLczun65JhyeAvrfeKrsFHOuldcnyJxf+Q7L+4s33JOvTv3Fjsv77t/08Wa+F4Xxmv0DSfEnrzGxNtuxm9Yf8STO7VtJWSXNr0yKAIgwZdnd/XtKgg/SS4l0hA7xPcbksEARhB4Ig7EAQhB0IgrADQRzX5bJAFKffmx4Hn35aehx9zXXpcfgLt92QW2te/EJy3UqxZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIPgpaaACdlL6EpUzXkjXZ31wbW7t3qkfq6gniSmbAYiwA2EQdiAIwg4EQdiBIAg7EARhB4Lg++xABbynJ1l/dWb6+pX7ms5OVA9X0NHQ2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBBDht3MJpvZT8xso5ltMLMbs+W3mtl2M1uT3WbXvl3gfaKvN3nzI4dzb7UynItqeiR9zd1fNrNxklab2Yqsdre731mz7gAUZjjzs++QtCN73G1mmyRNqnVjAIp1XJ/ZzWyKpHMlrcwWXW9ma81ssZlNyFmnzcw6zazziA5V1SyAyg077GZ2iqSnJH3F3fdLul/SmZKmq3/P/53B1nP3dndvdffWkRpdQMsAKjGssJvZSPUH/TF3/74kuftOd+919z5JiyTNqF2bAKo1nLPxJulBSZvc/a4By1sGvOxTktYX3x6AogznbPwFkuZLWmdma7JlN0uaZ2bTJbmkLZKuq0mHAAoxnLPxz0sa7Heony2+HQC1whV0QBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIMw9PbVsoRsz2y1p64BFp0naU7cGjk+j9taofUn0Vqkie/sDd//QYIW6hv09GzfrdPfW0hpIaNTeGrUvid4qVa/eOIwHgiDsQBBlh7295O2nNGpvjdqXRG+VqktvpX5mB1A/Ze/ZAdQJYQeCKCXsZjbLzH5lZq+Y2U1l9JDHzLaY2bpsGurOkntZbGa7zGz9gGXNZrbCzLqy+0Hn2Cupt4aYxjsxzXip713Z05/X/TO7mTVJ+rWkv5K0TdIqSfPcfWNdG8lhZlsktbp76RdgmNlFkg5Ietjdz86W3SFpr7svzP6hnODu/9ggvd0q6UDZ03hnsxW1DJxmXNKVkq5Rie9doq+5qsP7VsaefYakV9x9s7sflvS4pDkl9NHw3P05SXuPWTxH0pLs8RL1/89Sdzm9NQR33+HuL2ePuyW9M814qe9doq+6KCPskyS9NuD5NjXWfO8u6cdmttrM2spuZhAT3X1H9vh1SRPLbGYQQ07jXU/HTDPeMO9dJdOfV4sTdO91obv/iaTLJX05O1xtSN7/GayRxk6HNY13vQwyzfi7ynzvKp3+vFplhH27pMkDnn84W9YQ3H17dr9L0jI13lTUO9+ZQTe731VyP+9qpGm8B5tmXA3w3pU5/XkZYV8laaqZfcTMRkm6WtLyEvp4DzMbm504kZmNlXSZGm8q6uWSFmSPF0h6usRejtIo03jnTTOukt+70qc/d/e63yTNVv8Z+Vcl3VJGDzl9nSHpl9ltQ9m9SVqq/sO6I+o/t3GtpFMldUjqkvTfkpobqLdHJK2TtFb9wWopqbcL1X+IvlbSmuw2u+z3LtFXXd43LpcFguAEHRAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E8f/qWK0mCc2FgQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted: 9 actual: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted: 8 actual: 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted: 2 actual: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted: 8 actual: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now use keras"
      ],
      "metadata": {
        "id": "6eI1nOK-BntU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "# input_shape = (28, 28, 1)\n",
        "input_shape = (28 * 28, )\n",
        "\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "# x_train = np.expand_dims(x_train, -1)\n",
        "# x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Make sure images have shape (28 * 28, 1)\n",
        "x_train = x_train.reshape((-1, 28 * 28))\n",
        "x_test = x_test.reshape((-1, 28 * 28))\n",
        "# x_train = np.expand_dims(x_train, -1)\n",
        "# x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hfqvzNMdSei",
        "outputId": "82d7d6c5-ca49-4575-c1b2-74fa1bbc569a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 784)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Dense(30, activation=\"sigmoid\"), # 30 hidden neurons\n",
        "        layers.Dense(10, activation=\"softmax\"), # 10 output neurons, 1 for each class\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9OIaWjACkzE",
        "outputId": "11dbdcfc-5052-45a8-dcca-b78e7340d9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 30)                23550     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                310       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,860\n",
            "Trainable params: 23,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.MeanSquaredError(reduction=keras.losses.Reduction.SUM), \n",
        "    optimizer=keras.optimizers.SGD(learning_rate=3), \n",
        "    metrics=[keras.metrics.CategoricalAccuracy()]\n",
        ")\n",
        "# Default reduction is average over dims followed by average over batch size\n",
        "# see Scratch section\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train, batch_size=10, epochs=30, validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu8rcweiEEKN",
        "outputId": "0e3b0b61-6304-4be7-a0ad-2b119eb63804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "5400/5400 [==============================] - 11s 2ms/step - loss: 0.1690 - categorical_accuracy: 0.8878 - val_loss: 0.1235 - val_categorical_accuracy: 0.9218\n",
            "Epoch 2/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.1239 - categorical_accuracy: 0.9212 - val_loss: 0.0869 - val_categorical_accuracy: 0.9458\n",
            "Epoch 3/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.1142 - categorical_accuracy: 0.9275 - val_loss: 0.0907 - val_categorical_accuracy: 0.9433\n",
            "Epoch 4/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.1107 - categorical_accuracy: 0.9310 - val_loss: 0.0843 - val_categorical_accuracy: 0.9477\n",
            "Epoch 5/30\n",
            "5400/5400 [==============================] - 12s 2ms/step - loss: 0.1011 - categorical_accuracy: 0.9365 - val_loss: 0.0810 - val_categorical_accuracy: 0.9503\n",
            "Epoch 6/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.1015 - categorical_accuracy: 0.9367 - val_loss: 0.0771 - val_categorical_accuracy: 0.9522\n",
            "Epoch 7/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.0950 - categorical_accuracy: 0.9413 - val_loss: 0.0841 - val_categorical_accuracy: 0.9483\n",
            "Epoch 8/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.0943 - categorical_accuracy: 0.9419 - val_loss: 0.0911 - val_categorical_accuracy: 0.9448\n",
            "Epoch 9/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0896 - categorical_accuracy: 0.9451 - val_loss: 0.0733 - val_categorical_accuracy: 0.9547\n",
            "Epoch 10/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0889 - categorical_accuracy: 0.9455 - val_loss: 0.0747 - val_categorical_accuracy: 0.9532\n",
            "Epoch 11/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.0847 - categorical_accuracy: 0.9475 - val_loss: 0.0984 - val_categorical_accuracy: 0.9407\n",
            "Epoch 12/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0862 - categorical_accuracy: 0.9472 - val_loss: 0.0698 - val_categorical_accuracy: 0.9562\n",
            "Epoch 13/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0791 - categorical_accuracy: 0.9516 - val_loss: 0.0769 - val_categorical_accuracy: 0.9540\n",
            "Epoch 14/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.0803 - categorical_accuracy: 0.9510 - val_loss: 0.0886 - val_categorical_accuracy: 0.9462\n",
            "Epoch 15/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0785 - categorical_accuracy: 0.9524 - val_loss: 0.0771 - val_categorical_accuracy: 0.9512\n",
            "Epoch 16/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0782 - categorical_accuracy: 0.9524 - val_loss: 0.0759 - val_categorical_accuracy: 0.9530\n",
            "Epoch 17/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.0772 - categorical_accuracy: 0.9527 - val_loss: 0.0776 - val_categorical_accuracy: 0.9510\n",
            "Epoch 18/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0729 - categorical_accuracy: 0.9558 - val_loss: 0.0694 - val_categorical_accuracy: 0.9575\n",
            "Epoch 19/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0737 - categorical_accuracy: 0.9548 - val_loss: 0.0753 - val_categorical_accuracy: 0.9538\n",
            "Epoch 20/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0738 - categorical_accuracy: 0.9555 - val_loss: 0.0725 - val_categorical_accuracy: 0.9577\n",
            "Epoch 21/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0727 - categorical_accuracy: 0.9559 - val_loss: 0.0806 - val_categorical_accuracy: 0.9503\n",
            "Epoch 22/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0754 - categorical_accuracy: 0.9547 - val_loss: 0.0796 - val_categorical_accuracy: 0.9527\n",
            "Epoch 23/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0726 - categorical_accuracy: 0.9560 - val_loss: 0.0721 - val_categorical_accuracy: 0.9558\n",
            "Epoch 24/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0693 - categorical_accuracy: 0.9584 - val_loss: 0.0673 - val_categorical_accuracy: 0.9608\n",
            "Epoch 25/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0704 - categorical_accuracy: 0.9575 - val_loss: 0.0749 - val_categorical_accuracy: 0.9550\n",
            "Epoch 26/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0671 - categorical_accuracy: 0.9595 - val_loss: 0.0777 - val_categorical_accuracy: 0.9548\n",
            "Epoch 27/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0691 - categorical_accuracy: 0.9581 - val_loss: 0.0723 - val_categorical_accuracy: 0.9553\n",
            "Epoch 28/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0653 - categorical_accuracy: 0.9609 - val_loss: 0.0704 - val_categorical_accuracy: 0.9577\n",
            "Epoch 29/30\n",
            "5400/5400 [==============================] - 10s 2ms/step - loss: 0.0672 - categorical_accuracy: 0.9600 - val_loss: 0.0714 - val_categorical_accuracy: 0.9587\n",
            "Epoch 30/30\n",
            "5400/5400 [==============================] - 9s 2ms/step - loss: 0.0693 - categorical_accuracy: 0.9584 - val_loss: 0.0780 - val_categorical_accuracy: 0.9542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb8a44044d0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "XDChC7W5IncP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bc28b8-7aa4-4fb7-b07d-adb3ac061e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.2533735930919647\n",
            "Test accuracy: 0.9520999789237976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scratch"
      ],
      "metadata": {
        "id": "3Rdlif3b7E1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upto = 2\n",
        "for img, lab in te:\n",
        "    print(img.shape, lab.shape)\n",
        "    upto -= 1\n",
        "    if upto < 1: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7AMZaNnZ-0B",
        "outputId": "968f4111-2c84-494e-9347-42a4ab2f58b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 1) ()\n",
            "(784, 1) ()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upto = 2\n",
        "for img, lab in te:\n",
        "    pred = net.feedforward(img)\n",
        "    print(pred, lab)\n",
        "    upto -= 1\n",
        "    if upto < 1: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUTgRNPCaMuB",
        "outputId": "30803a47-4d45-4a86-86f3-fb81239dca16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.94852847e-16]\n",
            " [9.99287714e-01]\n",
            " [2.78055426e-08]\n",
            " [3.83721098e-06]\n",
            " [3.54855330e-06]\n",
            " [1.76447776e-10]\n",
            " [6.69120469e-05]\n",
            " [3.00309416e-03]\n",
            " [7.69461463e-07]\n",
            " [9.79708934e-07]] 1\n",
            "[[9.95514280e-01]\n",
            " [2.24533820e-05]\n",
            " [2.34155561e-07]\n",
            " [2.71358388e-07]\n",
            " [4.68065814e-04]\n",
            " [2.79598157e-07]\n",
            " [1.26880537e-04]\n",
            " [6.04709061e-08]\n",
            " [6.76297748e-08]\n",
            " [5.61063683e-05]] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img.reshape((28, 28)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "XqoJ8CJTawXt",
        "outputId": "164315c7-7492-47b7-c823-954f063b1065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb92544e710>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upto = 2\n",
        "for img, lab in te:\n",
        "    pred = net.feedforward(img)\n",
        "    pred_lab = np.argmax(pred)\n",
        "    print(pred_lab, lab)\n",
        "    upto -= 1\n",
        "    if upto < 1: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iay5GFOKbNEB",
        "outputId": "300d3d42-604d-47c6-f9a6-6f0fef0adbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 4\n",
            "1 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upto = 1\n",
        "z = zip([1, 2], [4, 5])\n",
        "for x, y in z:\n",
        "    print(x, y)\n",
        "    upto -= 1\n",
        "    if upto < 1: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJP5Fa31YXIT",
        "outputId": "58318e81-bf25-4171-dae4-149ea61cc58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = list(z)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpHQFtI8Yk5a",
        "outputId": "b2d457ac-2dd6-4405-d153-928cc7e80a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "For some reason this results in corrupted files\n",
        "'''\n",
        "\n",
        "#!wget https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz \n",
        "#!wget https://github.com/MichalDanielDobrzanski/DeepLearningPython/blob/master/mnist.pkl.gz "
      ],
      "metadata": {
        "id": "eED9FDQkBdUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(model(x_test), axis=1)\n",
        "true = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "w78W39l0Gn6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test[:2]\n",
        "sum(pred == true) / len(y_test)\n",
        "# m = keras.metrics.Accuracy()\n",
        "# m.update_state(np.expand_dims(pred, axis=1), np.expand_dims(true, axis=1))\n",
        "# m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT4gHLyHS7Ly",
        "outputId": "f7b341ce-be13-44d4-e953-111f6d816e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1151"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.expand_dims(pred, axis=1)[:3]\n",
        "# pred[:3]\n",
        "print(y_test[:3])\n",
        "model(x_test[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hW9KAw_xBP7",
        "outputId": "1bbfb57e-9941-41aa-80e3-806d7980a107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=float32, numpy=\n",
              "array([[0.02702972, 0.1902639 , 0.05914813, 0.05440875, 0.09455995,\n",
              "        0.17240931, 0.03179046, 0.12296242, 0.11256479, 0.13486259],\n",
              "       [0.02055437, 0.18911885, 0.05087472, 0.05972384, 0.09683575,\n",
              "        0.17117271, 0.03097234, 0.14020933, 0.11615209, 0.12438594],\n",
              "       [0.02596499, 0.19241272, 0.05001093, 0.06918433, 0.09283505,\n",
              "        0.19412108, 0.02545374, 0.12864646, 0.10250535, 0.11886541]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = keras.metrics.CategoricalAccuracy()\n",
        "m.update_state(model(x_test[:9]), y_test[:9])\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R20oo8vjy007",
        "outputId": "89f09d27-c164-4045-bd89-3b34c40c6dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22222222"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(true[:9])\n",
        "print(pred[:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpNrS2QK1VmI",
        "outputId": "21e56d49-88a1-45fd-b57a-0cfe5537c9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 0 4 1 4 9 5]\n",
            "[1 1 5 5 5 1 5 1 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model(x_test[:9]).numpy()\n",
        "y_test[:9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zJuR43B1o97",
        "outputId": "00337da5-4edd-4c64-b881-40af0e477da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = keras.losses.MeanSquaredError()\n",
        "mse(y_train[:2], model(x_train[:2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_mgVwM2K0lK",
        "outputId": "a4252d17-6e27-415c-f369-d2daa074d788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0016072472>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = [[0.3, 1.], [0., 0.]]\n",
        "y_pred = [[1., 1.], [1., 0.99]]\n",
        "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
        "mse = keras.losses.MeanSquaredError(reduction=keras.losses.Reduction.SUM)\n",
        "mse(y_true, y_pred).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXJJ_otVLHbe",
        "outputId": "7b9c2171-c3d2-4882-cc0e-cdb10dff3814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.23505"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.square(np.array(y_true) - np.array(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0LDHojoLqgo",
        "outputId": "3a94b4e5-3a3b-46ba-b55b-b039feea0c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49  , 0.    ],\n",
              "       [1.    , 0.9801]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.average(np.square(np.array(y_true) - np.array(y_pred)), axis=1)\n",
        "np.sum(np.square(np.array(y_true) - np.array(y_pred)), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmVR7RN2PCiJ",
        "outputId": "0eb15440-6da3-4bca-9e82-fa7643c8a478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.49  , 1.9801])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.average(np.average(np.square(np.array(y_true) - np.array(y_pred)), axis=1))\n",
        "np.average(np.sum(np.square(np.array(y_true) - np.array(y_pred)), axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkQt0wISPvBQ",
        "outputId": "5e66980a-0abf-4a81-f074-3692cf02f9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.23505"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cwECjimV6_Dg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}